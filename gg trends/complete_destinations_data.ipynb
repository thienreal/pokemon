{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc6f4f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Libraries loaded\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('✓ Libraries loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3095e131",
   "metadata": {},
   "source": [
    "## 1. Load và consolidate dữ liệu từ tất cả CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee8fafae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 242 CSV files\n",
      "Using anchor from dest_trends_raw/dest_group_001.csv\n",
      "Processed 50/242 files\n",
      "Processed 100/242 files\n",
      "Processed 150/242 files\n",
      "Processed 100/242 files\n",
      "Processed 150/242 files\n",
      "Processed 200/242 files\n",
      "\n",
      "Successfully processed 242 files\n",
      "Anchor values preserved from first file\n",
      "Processed 200/242 files\n",
      "\n",
      "Successfully processed 242 files\n",
      "Anchor values preserved from first file\n"
     ]
    }
   ],
   "source": [
    "# Cấu hình\n",
    "CSV_DIR = 'dest_trends_raw'\n",
    "ANCHOR = 'Rau má'\n",
    "START_DATE = 'thg 1 2011'  # Tháng 1 năm 2011\n",
    "\n",
    "# Tìm tất cả file CSV\n",
    "csv_files = sorted(glob.glob(os.path.join(CSV_DIR, 'dest_group_*.csv')))\n",
    "print(f\"Found {len(csv_files)} CSV files\")\n",
    "\n",
    "# Load và NORMALIZE từng file trước khi merge\n",
    "normalized_dfs = []\n",
    "anchor_df = None  # Lưu anchor values từ file đầu tiên\n",
    "\n",
    "for i, csv_file in enumerate(csv_files):\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file)\n",
    "        \n",
    "        # Lưu anchor values từ file đầu tiên\n",
    "        if anchor_df is None and ANCHOR in df.columns:\n",
    "            anchor_df = df[['date', ANCHOR]].copy()\n",
    "            print(f\"Using anchor from {csv_file}\")\n",
    "        \n",
    "        # Normalize ngay trong file này\n",
    "        if ANCHOR in df.columns:\n",
    "            anchor_values = df[ANCHOR].replace(0, np.nan)\n",
    "            \n",
    "            # Normalize tất cả columns (trừ date và anchor)\n",
    "            df_normalized = df[['date']].copy()\n",
    "            for col in df.columns:\n",
    "                if col not in ['date', ANCHOR]:\n",
    "                    df_normalized[col] = (df[col] / anchor_values) * 100\n",
    "            \n",
    "            normalized_dfs.append(df_normalized)\n",
    "        \n",
    "        if (i + 1) % 50 == 0:\n",
    "            print(f\"Processed {i + 1}/{len(csv_files)} files\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {csv_file}: {e}\")\n",
    "\n",
    "print(f\"\\nSuccessfully processed {len(normalized_dfs)} files\")\n",
    "print(f\"Anchor values preserved from first file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e95be6",
   "metadata": {},
   "source": [
    "## 2. Merge tất cả dữ liệu vào một DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1fc3db97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Merge completed\n",
      "Combined DataFrame shape: (264, 969)\n",
      "Total columns: 969\n",
      "Total rows (months): 264\n"
     ]
    }
   ],
   "source": [
    "# Merge tất cả normalized dataframes\n",
    "# Sử dụng concat trên columns với outer join\n",
    "\n",
    "prepared_dfs = []\n",
    "for df in normalized_dfs:\n",
    "    df_indexed = df.set_index('date')\n",
    "    prepared_dfs.append(df_indexed)\n",
    "\n",
    "# Concatenate\n",
    "combined_df = pd.concat(prepared_dfs, axis=1, join='outer')\n",
    "\n",
    "# Reset index\n",
    "combined_df = combined_df.reset_index()\n",
    "\n",
    "# Xóa duplicate columns\n",
    "combined_df = combined_df.loc[:, ~combined_df.columns.duplicated()]\n",
    "\n",
    "# Thêm anchor column từ anchor_df\n",
    "if anchor_df is not None:\n",
    "    combined_df = pd.merge(combined_df, anchor_df, on='date', how='left')\n",
    "    # Đặt Rau má = 100 cho tất cả rows (vì nó là anchor)\n",
    "    combined_df[ANCHOR] = 100.0\n",
    "\n",
    "print(f\"✓ Merge completed\")\n",
    "print(f\"Combined DataFrame shape: {combined_df.shape}\")\n",
    "print(f\"Total columns: {len(combined_df.columns)}\")\n",
    "print(f\"Total rows (months): {len(combined_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b9e5eb",
   "metadata": {},
   "source": [
    "## 3. Cắt dữ liệu từ 1/1/2011 trở đi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ae37f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Filtered data from 2011 onwards\n",
      "New shape: (180, 969)\n",
      "Date range: thg 1 2011 to thg 9 2025\n",
      "Total months: 180\n"
     ]
    }
   ],
   "source": [
    "# Filter dữ liệu từ 2011 trở đi (bằng cách extract năm từ date string)\n",
    "def extract_year(date_str):\n",
    "    \"\"\"Extract year from Vietnamese date format like 'thg 1 2011'\"\"\"\n",
    "    try:\n",
    "        return int(date_str.split()[-1])\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "combined_df['year'] = combined_df['date'].apply(extract_year)\n",
    "\n",
    "# Filter từ 2011 trở đi\n",
    "combined_df = combined_df[combined_df['year'] >= 2011].copy()\n",
    "\n",
    "# Drop cột year tạm\n",
    "combined_df = combined_df.drop('year', axis=1)\n",
    "\n",
    "# Sort theo date để đảm bảo thứ tự đúng\n",
    "combined_df = combined_df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "print(f\"✓ Filtered data from 2011 onwards\")\n",
    "print(f\"New shape: {combined_df.shape}\")\n",
    "print(f\"Date range: {combined_df['date'].iloc[0]} to {combined_df['date'].iloc[-1]}\")\n",
    "print(f\"Total months: {len(combined_df)}\")\n",
    "\n",
    "# Lưu vào normalized_df để giữ tên biến nhất quán\n",
    "normalized_df = combined_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f571c06",
   "metadata": {},
   "source": [
    "## 4. Normalize traffic theo anchor (Rau má)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d5dcaea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data already normalized in previous step\n",
      "Total destinations: 968\n",
      "Anchor column 'Rau má' = 100 (reference)\n",
      "\n",
      "✓ Cleaned NaN/Inf values\n"
     ]
    }
   ],
   "source": [
    "# Dữ liệu đã được normalize ở bước trước\n",
    "# Cell này chỉ để kiểm tra và xử lý NaN/Inf\n",
    "\n",
    "print(f\"✓ Data already normalized in previous step\")\n",
    "print(f\"Total destinations: {len(normalized_df.columns) - 1}\")\n",
    "print(f\"Anchor column '{ANCHOR}' = 100 (reference)\")\n",
    "\n",
    "# Xử lý NaN/Inf nếu có\n",
    "normalized_df = normalized_df.replace([np.inf, -np.inf], np.nan)\n",
    "normalized_df = normalized_df.fillna(0)\n",
    "\n",
    "print(f\"\\n✓ Cleaned NaN/Inf values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ba993f",
   "metadata": {},
   "source": [
    "## 5. Thống kê tổng quát"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bf7c9330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for all 968 destinations:\n",
      "\n",
      "Top 10 by Average Interest:\n",
      "          Destination         Mean      Median          Max  Coverage %\n",
      "897          Lam Kinh  1067.921986  163.333333  8500.000000  100.000000\n",
      "849           Bình An   807.656986  750.000000  1700.000000  100.000000\n",
      "730          Phú Quốc   643.394484  664.583333  1300.000000   98.888889\n",
      "100            Hồ Tây   400.804520  324.500000  1200.000000  100.000000\n",
      "375        Đồng Thông   334.366562  295.553360  1000.000000  100.000000\n",
      "647  Thành phố Hà Nội   286.560800  163.392857  1733.333333  100.000000\n",
      "777      Phượng Hoàng   176.851879  150.000000   833.333333  100.000000\n",
      "628             Ba Vì   175.048899  159.411765   500.000000  100.000000\n",
      "941           Tam Đảo   151.717730  142.857143   375.000000  100.000000\n",
      "869            Mũi Né   143.361527  136.363636   550.000000  100.000000\n",
      "\n",
      "Overall Summary:\n",
      "Total time periods: 180\n",
      "Total destinations: 968\n",
      "Average coverage: 27.25%\n"
     ]
    }
   ],
   "source": [
    "# Thống kê cho mỗi destination\n",
    "stats_list = []\n",
    "\n",
    "for col in normalized_df.columns:\n",
    "    if col != 'date':\n",
    "        non_zero = normalized_df[col][normalized_df[col] > 0]\n",
    "        stats_list.append({\n",
    "            'Destination': col,\n",
    "            'Mean': normalized_df[col].mean(),\n",
    "            'Median': normalized_df[col].median(),\n",
    "            'Max': normalized_df[col].max(),\n",
    "            'Min': normalized_df[col].min(),\n",
    "            'Std Dev': normalized_df[col].std(),\n",
    "            'Non-zero Count': len(non_zero),\n",
    "            'Coverage %': (len(non_zero) / len(normalized_df)) * 100\n",
    "        })\n",
    "\n",
    "stats_df = pd.DataFrame(stats_list)\n",
    "\n",
    "print(f\"Statistics for all {len(stats_df)} destinations:\")\n",
    "print(f\"\\nTop 10 by Average Interest:\")\n",
    "print(stats_df.nlargest(10, 'Mean')[['Destination', 'Mean', 'Median', 'Max', 'Coverage %']])\n",
    "\n",
    "print(f\"\\nOverall Summary:\")\n",
    "print(f\"Total time periods: {len(normalized_df)}\")\n",
    "print(f\"Total destinations: {len(stats_df)}\")\n",
    "print(f\"Average coverage: {stats_df['Coverage %'].mean():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7783feaa",
   "metadata": {},
   "source": [
    "## 6. Preview dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ef08fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of normalized data:\n",
      "         date  Chợ Trung tâm Ba Chẽ  Miếu Ông – Miếu Bà  Phố đi bộ Tiên Yên  \\\n",
      "0  thg 1 2011                   0.0                 0.0                 0.0   \n",
      "1  thg 1 2012                   0.0                 0.0                 0.0   \n",
      "2  thg 1 2013                   0.0                 0.0                 0.0   \n",
      "3  thg 1 2014                   0.0                 0.0                 0.0   \n",
      "4  thg 1 2015                   0.0                 0.0                 0.0   \n",
      "\n",
      "   căn cứ địa cách mạng Hải Chi  Văn hóa, Thể thao các dân tộc vùng Đông Bắc  \\\n",
      "0                           0.0                                          0.0   \n",
      "1                           0.0                                          0.0   \n",
      "2                           0.0                                          0.0   \n",
      "3                           0.0                                          0.0   \n",
      "4                           0.0                                          0.0   \n",
      "\n",
      "   Đền thờ Đức ông Hoàng Cần  Chợ Tiên Yên  Thác Pạc Sủi  \\\n",
      "0                        0.0           0.0           0.0   \n",
      "1                        0.0           0.0           0.0   \n",
      "2                        0.0           0.0           0.0   \n",
      "3                        0.0           0.0           0.0   \n",
      "4                        0.0           0.0           0.0   \n",
      "\n",
      "   Chợ Trung tâm huyện Bình Liêu  \n",
      "0                            0.0  \n",
      "1                            0.0  \n",
      "2                            0.0  \n",
      "3                            0.0  \n",
      "4                            0.0  \n",
      "\n",
      "...and 959 more columns\n",
      "\n",
      "Data types:\n",
      "float64    968\n",
      "object       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Hiển thị một vài rows đầu\n",
    "print(\"First 5 rows of normalized data:\")\n",
    "print(normalized_df.iloc[:5, :10])  # Hiển thị 10 cột đầu\n",
    "\n",
    "print(f\"\\n...and {len(normalized_df.columns) - 10} more columns\")\n",
    "\n",
    "# Hiển thị thông tin về data types\n",
    "print(f\"\\nData types:\")\n",
    "print(normalized_df.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603d6c11",
   "metadata": {},
   "source": [
    "## 7. Lưu dữ liệu đã consolidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac6f3690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved consolidated data to 'complete_destinations_normalized.csv'\n",
      "File size: 1.22 MB\n",
      "✓ Saved statistics to 'destinations_statistics.csv'\n"
     ]
    }
   ],
   "source": [
    "# Lưu consolidated data\n",
    "output_file = 'complete_destinations_normalized.csv'\n",
    "normalized_df.to_csv(output_file, index=False)\n",
    "print(f\"✓ Saved consolidated data to '{output_file}'\")\n",
    "print(f\"File size: {os.path.getsize(output_file) / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "# Lưu statistics\n",
    "stats_file = 'destinations_statistics.csv'\n",
    "stats_df.to_csv(stats_file, index=False)\n",
    "print(f\"✓ Saved statistics to '{stats_file}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
