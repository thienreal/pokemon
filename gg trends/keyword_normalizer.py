#!/usr/bin/env python3
import re
import os
import sys
import argparse
import logging
import pandas as pd

logging.basicConfig(level=logging.INFO, format='[%(levelname)s] %(message)s')

PREFIX_PATTERNS = [
    r'^Khu\s+di\s+tÃ­ch\s+lá»‹ch\s+sá»­\s+vÃ \s+Danh\s+tháº¯ng\s+',
    r'^Di\s+tÃ­ch\s+lá»‹ch\s+sá»­\s+quá»‘c\s+gia\s+Ä‘áº·c\s+biá»‡t\s+',
    r'^Khu\s+di\s+tÃ­ch\s+lá»‹ch\s+sá»­\s+-\s+VVÄƒn\s+hÃ³a\s+',
    r'^Khu\s+du\s+lá»‹ch\s+vÃ \s+vÆ°á»n\s+Quá»‘c\s+gia\s+',
    r'^Äiá»ƒm\s+du\s+lá»‹ch\s+Di\s+tÃ­ch\s+Lá»‹ch\s+sá»­\s+',
    r'^Di\s+tÃ­ch\s+lá»‹ch\s+sá»­\s+-\s+vÄƒn\s+hÃ³a\s+',
    r'^Du\s+lá»‹ch\s+Suá»‘i\s+khoÃ¡ng\s+nÃ³ng\s+',
    r'^Khu\s+báº£o\s+tá»“n\s+thiÃªn\s+nhiÃªn\s+',
    r'^Khu\s+du\s+lá»‹ch\s+sinh\s+thÃ¡i\s+',
    r'^Khu\s+du\s+lich\s+sinh\s+thÃ¡i\s+',
    r'^Khu\s+vui\s+chÆ¡i\s+giáº£i\s+trÃ­\s+',
    r'^LÃ ng\s+nghá»\s+truyá»n\s+thá»‘ng\s+',
    r'^Quáº§n\s+thá»ƒ\s+khu\s+di\s+tÃ­ch\s+',
    r'^Cá»¥m\s+di\s+tÃ­ch\s+lá»‹ch\s+sá»­\s+',
    r'^Trung\s+tÃ¢m\s+thÆ°Æ¡ng\s+máº¡i\s+',
    r'^Trung\s+tÃ¢m\s+vÄƒn\s+hÃ³a\s+',
    r'^Di\s+tÃ­ch\s+lá»‹ch\s+sá»­\s+',
    r'^Khu\s+nghá»‰\s+dÆ°á»¡ng\s+',
    r'^Khu\s+trung\s+tÃ¢m\s+',
    r'^VÆ°á»n\s+Quá»‘c\s+gia\s+',
    r'^Khu\s+sinh\s+thÃ¡i\s+',
    r'^Khu\s+lÆ°u\s+niá»‡m\s+',
    r'^Äiá»ƒm\s+du\s+lá»‹ch\s+',
    r'^Khu\s+du\s+lá»‹ch\s+',
    r'^Khu\s+di\s+tÃ­ch\s+',
    r'^Cá»¥m\s+di\s+tÃ­ch\s+',
    r'^Trung\s+tÃ¢m\s+',
    r'^QuÃ¡n\s+CafÃ©\s+',
    r'^Quáº§n\s+thá»ƒ\s+',
    r'^Di\s+tÃ­ch\s+',
]

def normalize_name(name: str) -> tuple[str, str | None]:
    s = name.strip()
    removed = None
    for pat in PREFIX_PATTERNS:
        m = re.match(pat, s, flags=re.IGNORECASE)
        if m:
            removed = m.group(0)
            s = re.sub(pat, '', s, flags=re.IGNORECASE).strip()
            break
    # Thu gá»n dáº¥u ná»‘i dÃ i kiá»ƒu " - "
    s = re.sub(r'\s*-\s*', ' - ', s)
    # Loáº¡i bá» pháº§n trong ngoáº·c Ä‘á»ƒ rÃºt gá»n: ( ... )
    s = re.sub(r'\([^\)]*\)', '', s).strip()
    # Loáº¡i dáº¥u pháº©y/dáº¥u cháº¥m á»Ÿ cuá»‘i
    s = re.sub(r'[\s,.;]+$', '', s)
    # RÃºt gá»n khoáº£ng tráº¯ng thá»«a
    s = re.sub(r'\s+', ' ', s).strip()
    # Giá»¯ nguyÃªn tiáº¿ng Viá»‡t cÃ³ dáº¥u, chá»‰ loáº¡i khoáº£ng tráº¯ng thá»«a
    return s, removed

def main():
    ap = argparse.ArgumentParser(description='Normalize destination names and output mapping')
    ap.add_argument('--input', default='../tourism.csv', help='Source CSV with name,province')
    ap.add_argument('--delimiter', default=';', help='CSV delimiter (default ;)')
    ap.add_argument('--output', default='keyword_mapping.csv', help='Output mapping CSV')
    args = ap.parse_args()

    if not os.path.exists(args.input):
        logging.error(f'Input not found: {args.input}')
        sys.exit(1)

    df = pd.read_csv(args.input, delimiter=args.delimiter)
    if 'name' not in df.columns:
        logging.error("CSV must contain 'name' column")
        sys.exit(1)
    
    # Check if province column exists
    has_province = 'province' in df.columns

    # First pass: normalize all names
    rows = []
    for idx, row in df.iterrows():
        name_clean = str(row['name']).strip()
        if not name_clean:
            continue
        norm, removed = normalize_name(name_clean)
        province = str(row['province']).strip() if has_province and pd.notna(row.get('province')) else ''
        rows.append({
            'row_index': idx + 1,
            'original_name': name_clean,
            'normalized_name': norm,
            'province': province,
            'removed_prefix': removed or ''
        })
    
    # Second pass: detect duplicates and append province to normalized_name
    from collections import defaultdict
    norm_count = defaultdict(list)
    for r in rows:
        norm_count[r['normalized_name']].append(r)
    
    # Track duplicates before dedup
    original_count = len(rows)
    duplicates_resolved = 0
    exact_duplicates_removed = 0
    
    final_rows = []
    seen_norm_province = set()
    
    for norm, entries in norm_count.items():
        if len(entries) > 1:
            duplicates_resolved += 1
            # Append province to normalized_name for all duplicates
            for entry in entries:
                if entry['province']:
                    entry['normalized_name'] = f"{norm} {entry['province']}"
                
                # Check if this normalized_name + province combo already exists
                key = (entry['normalized_name'], entry['province'])
                if key not in seen_norm_province:
                    seen_norm_province.add(key)
                    final_rows.append(entry)
                    logging.info(f"  Kept: '{entry['original_name']}' â†’ '{entry['normalized_name']}'")
                else:
                    exact_duplicates_removed += 1
                    logging.info(f"  Removed duplicate: '{entry['original_name']}' (same as existing)")
        else:
            # No duplicates, keep as is
            entry = entries[0]
            key = (entry['normalized_name'], entry['province'])
            if key not in seen_norm_province:
                seen_norm_province.add(key)
                final_rows.append(entry)
    
    if duplicates_resolved > 0:
        logging.warning(f"âš ï¸  Found {duplicates_resolved} duplicate keyword groups")
        logging.warning(f"   Removed {exact_duplicates_removed} exact duplicates (same name + province)")
        logging.warning(f"   Final count: {len(final_rows)} unique destinations (from {original_count})")
    
    rows = final_rows
    
    out = pd.DataFrame(rows)
    out.to_csv(args.output, index=False, encoding='utf-8-sig')
    logging.info(f'ðŸ’¾ Saved mapping -> {args.output} ({len(out)} rows)')

if __name__ == '__main__':
    main()
